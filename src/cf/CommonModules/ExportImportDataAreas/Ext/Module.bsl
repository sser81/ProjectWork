#Region Public

// Exports application data to a ZIP archive. Later, the data can be imported
//  to another infobase or data areas by using function
//  DataAreaExportImport.ImportCurrentDataAreaFromArchive().
//
// Parameters:
//	DataAddress - String - a temporary storage address where the result must be stored, if this parameter is filled in
//	ExportModeForTechnicalSupport - Boolean - export flag in the mode for technical support
//	ConfigurationSchemaData - BinaryData, Undefined - Configuration schema binary data generated by method
//	   ConfigurationSchema.SchemaBinaryData(True, False).
//	UploadFileName - String, Undefined - Custom export file name (ZIP).
//	  If not specified, use the name of the new temp file.
//	UploadExtensionData - Boolean - Flag indicating whether the original data of custom extensions has been exported. 
//  ExportingParameters - Structure, Undefined - Export parameters.:
//    * UploadRegisteredChangesForExchangePlanNodes - Boolean - Include registered changes for exchange plan nodes in the export (the default value is False). 
//    * StateID - UUID, Undefined - If passed, the execution state will be recorded during execution and progress will be calculated. ID will be used as the entry key in the ExportImportDataAreasStates register.    
// 
// Returns:		
//  Structure - with the following fields::
//  * FileName - String - Archive file name.
//  * Warnings - Array of String - User notifications following the export.
//
Function UploadCurAreaToArchive(Val DataAddress = Undefined,
		ExportModeForTechnicalSupport = False,
		ConfigurationSchemaData = Undefined,
		UploadFileName = Undefined,
		UploadExtensionData = False,
		ExportingParameters = Undefined) Export
		
	SetPrivilegedMode(True);

	DataModelTypes = GetAreaDataModelTypes();
	TypesOfSharedData = ExportImportDataInternalEvents.GetSharedDataTypesThatSupportLinkMappingWhenLoading();
	 
	If Not ValueIsFilled(ExportingParameters) Then
		ExportingParameters = New Structure();
	EndIf;	
	ExportingParameters.Insert("TypesToExport", DataModelTypes);
	ExportingParameters.Insert("UnloadedTypesOfSharedData", TypesOfSharedData);
	ExportingParameters.Insert("UnloadUsers", True);
	ExportingParameters.Insert("ExportUserSettings", True);
	ExportingParameters.Insert("ExportModeForTechnicalSupport", ExportModeForTechnicalSupport);
	
	If ValueIsFilled(ConfigurationSchemaData) Then
		ExportingParameters.Insert("ConfigurationSchemaData", ConfigurationSchemaData);
	EndIf;

	If ValueIsFilled(UploadFileName) Then
		ExportingParameters.Insert("UploadFileName", UploadFileName);
	EndIf;
	
	If ValueIsFilled(UploadExtensionData) Then
		ExportingParameters.Insert("UploadExtensionData", UploadExtensionData);
	EndIf;

	Result = ExportImportData.UploadCurAreaDataToArchive(ExportingParameters);

	If DataAddress <> Undefined Then
		PutToTempStorage(Result, DataAddress);
	EndIf;

	Return Result;


EndFunction

// Exports application data to a ZIP archive file and puts the archive in a temporary storage.
//  Later, the data can be imported from the archive to other infobases or data areas with
//  DataAreaExportImport.ImportCurrentDataAreaFromArchive().
//  
//
// Parameters:
//	StorageAddress - String - a temporary storage address where the ZIP data archive file
//  	must be stored.
//
Procedure UnloadCurDataAreaToTemporaryStorage(StorageAddress) Export

	FileName = UploadCurAreaToArchive().FileName;

	Try

		UploadData_0 = New BinaryData(FileName);
		PutToTempStorage(UploadData_0, StorageAddress);

		ExportImportDataInternal.DeleteTempFile(FileName);

	Except

		ExceptionText = CloudTechnology.DetailedErrorText(ErrorInfo());

		ExportImportDataInternal.DeleteTempFile(FileName);

		Raise ExceptionText;

	EndTry;

EndProcedure

// Imports application data from a ZIP archive containing XML files.
//
// Parameters:
//  Archive - String, UUID - Full archive name or ID in the Service Manager.
//	UploadUsers - Boolean - indicates whether it is required to import user
//	CollapseElementsInUsersCatalog - Boolean - indicates whether it is required to collapse users
//	UserMatching - ValueTable - Details See ExportImportData.DownloadCurAreaDataFromArchive
//                                                ().
//	ExtensionData_ - Structure - Contains information on the area key and extensions to be restored:
//		* DataAreaKey - String - data area key
//		* RecoveryExtensions - Array - the list of extensions to be restored.
//  ImportParameters - Structure, Undefined - Import parameters.: 
//      * StateID - UUID, Undefined - if passed, the execution state will be recorded during execution and progress will be calculated. The ID will be used as an entry key in the ExportImportDataAreasStates register.
//		* ResultStorageAddress_ - String - If passed, the import result will be placed in the temporary storage at the specified address.
//    	* SkipExtensionsRestoring - Boolean - If true, extensions will not be restored before import.
//   
// Returns:		
//  Structure - with the following fields::
//  * Warnings - Array of String - User notifications following the import.
//
Function ImportCurrentAreaFromArchive(Val Archive,
		Val UploadUsers = False,
		Val CollapseElementsInUsersCatalog = False,
		UserMatching = Undefined,
		ExtensionData_ = Undefined,
		ImportParameters = Undefined) Export

	FullArchiveFileName_ = FullArchiveFileName_();
	FullArchive = Undefined;
	
	If TypeOf(Archive) = Type("String") Then
		
		ZIPReader = New ZipFileReader(Archive);
		FullArchiveElement = ZIPReader.Items.Find(FullArchiveFileName_);
		
		If FullArchiveElement <> Undefined Then
			
			TimeCatalog = GetTempFileName("zip") + GetPathSeparator();
			CreateDirectory(TimeCatalog);
			
			ZIPReader.Extract(FullArchiveElement, TimeCatalog);
			
			FullArchive = TimeCatalog + FullArchiveFileName_;
			
		EndIf;
		
	Else
		
		CopyArchive = ZipArchives.ReadArchive(Archive);
		RecordingFullArchive = CopyArchive.FilesDirectory[FullArchiveFileName_];
		
		If RecordingFullArchive <> Undefined Then
			
			TimeCatalog = GetTempFileName("zip") + GetPathSeparator();
			CreateDirectory(TimeCatalog);
			
			If RecordingFullArchive.CompressionMethod = 0 
				And RecordingFullArchive.UncompressedSize > 1024 * 1024 * 1024 Then
				
				// File is large. Read from the Service Manager during the data import.
				FullArchive = New Structure();
				FullArchive.Insert("IDOfSourceFile", Archive);
				
			Else
				
				// File is small, import the entire file.
				ZipArchives.ExtractFile(CopyArchive, FullArchiveFileName_, TimeCatalog);
				
				FullArchive = TimeCatalog + FullArchiveFileName_;
				
			EndIf;
			
		EndIf;
		
	EndIf;
	
	If FullArchive = Undefined Then
		
		ImportResult1 = ImportCurrentArea(
			Archive, 
			UploadUsers, 
			CollapseElementsInUsersCatalog, 
			UserMatching, 
			ExtensionData_, 
			"Ordinary", 
			Undefined,
			ImportParameters);
			
		ImportResult1.Delete("RefsMap");
		
	Else
		
		ImportResult1 = DownloadDifferentialCopy(
			FullArchive, 
			Archive,
			UploadUsers,
			CollapseElementsInUsersCatalog,
			UserMatching,
			ExtensionData_,
			ImportParameters);
			
		DeleteFiles(TimeCatalog);
		
	EndIf;
	
	PlaceImportingResultInTemporaryStorage(ImportParameters, ImportResult1);
		
	Return ImportResult1;

EndFunction

// Imports application data from the Service Manager file.
//
// Parameters:
//  FileID - UUID, Structure - Full name of the archive file or a structure with fields: 
//   
//	UploadUsers - Boolean - indicates whether it is required to import user
//	CollapseElementsInUsersCatalog - Boolean - indicates whether it is required to collapse users
//	UserMatching - ValueTable - Details See ExportImportData.DownloadCurAreaDataFromArchive
//                                                ().
//	ExtensionData_ - Structure - Contains information on the area key and extensions to be restored:
//		* DataAreaKey - String - data area key
//		* RecoveryExtensions - Array - the list of extensions to be restored.
//  ImportParameters - Structure, Undefined - Import parameters.: 
//   	* StateID - UUID, Undefined - if passed, the execution state will be recorded during execution and progress will be calculated. The ID will be used as an entry key in the ExportImportDataAreasStates register.
//		
// Returns:		
//  Structure - with the following fields::
//  * Warnings - Array of String - User notifications following the import.
//
Function ImportCurrentAreaFromVolume(
	Val FileID,
	Val UploadUsers = False,
	Val CollapseElementsInUsersCatalog = False,
	UserMatching = Undefined,
	ExtensionData_ = Undefined,
	ImportParameters = Undefined) Export
	
	SmallFileSize = 1024 * 1024 * 1024;
	
	If TypeOf(FileID) = Type("UUID") Then
		// Only one file.
		FileSize = SaaSOperations.GetFileSizeFromServiceManagerStorage(FileID);
		If FileSize = Undefined Or FileSize <= SmallFileSize Then
			// If a file is small or "Data transfer" subsystem is not integrated, import directly from the file.
			Archive = SaaSOperations.GetFileFromServiceManagerStorage(FileID);
		Else
			// Archives will be imported in chunks. 
			Archive = FileID
		EndIf;
		
		ImportResult1 = ImportCurrentAreaFromArchive(
			Archive,
			UploadUsers,
			CollapseElementsInUsersCatalog, 
			UserMatching, 
			ExtensionData_,
			ImportParameters);
			
		If TypeOf(Archive) = Type("String") And Not IsBlankString(Archive) Then
			Try
				DeleteFiles(Archive);
			Except
				WriteLogEvent(SaaSOperations.LogEventPreparingDataArea(), 
					EventLogLevel.Error,,, CloudTechnology.DetailedErrorText(ErrorInfo()));
			EndTry;
		EndIf;
		
		Return ImportResult1;
			
	EndIf;
		
	
	// Two IDs have been passed.
	FullCopyFileID = FileID.FullCopyFileID;
	DifferentialCopyFileID = FileID.DifferentialCopyFileID;
	
	FileSize = SaaSOperations.GetFileSizeFromServiceManagerStorage(FullCopyFileID);
	If FileSize = Undefined Or FileSize <= SmallFileSize Then
		FullArchive = SaaSOperations.GetFileFromServiceManagerStorage(FullCopyFileID);
	Else
		FullArchive = FullCopyFileID;
	EndIf;
	
	FileSize = SaaSOperations.GetFileSizeFromServiceManagerStorage(DifferentialCopyFileID);
	If FileSize = Undefined Or FileSize <= SmallFileSize Then
		DifferentialArchive = SaaSOperations.GetFileFromServiceManagerStorage(DifferentialCopyFileID);
	Else
		DifferentialArchive = DifferentialCopyFileID;
	EndIf;
	
	ImportResult1 = DownloadDifferentialCopy(
		FullArchive,
		DifferentialArchive,
		UploadUsers,
		CollapseElementsInUsersCatalog,
		UserMatching,
		ExtensionData_,
		ImportParameters);
	
	If TypeOf(FullArchive) = Type("String") And Not IsBlankString(FullArchive) Then
		Try
			DeleteFiles(FullArchive);
		Except
			WriteLogEvent(SaaSOperations.LogEventPreparingDataArea(), 
				EventLogLevel.Error,,, CloudTechnology.DetailedErrorText(ErrorInfo()));
		EndTry;
	EndIf;
	
	If TypeOf(DifferentialArchive) = Type("String") And Not IsBlankString(DifferentialArchive) Then
		Try
			DeleteFiles(DifferentialArchive);
		Except
			WriteLogEvent(SaaSOperations.LogEventPreparingDataArea(), 
				EventLogLevel.Error,,, CloudTechnology.DetailedErrorText(ErrorInfo()));
		EndTry;
	EndIf;
	
	Return ImportResult1;
	
EndFunction

// Imports application data from a differential copy.
//
// Parameters:
//  FullArchive - String, UUID, Structure - Filename, file ID, or file data retrieved from the file using ZIPArchives.ReadArchive().
//  DifferentialArchive - String, UUID, Structure - Filename, file ID, or file data retrieved from the file using ZIPArchives.ReadArchive().
//	UploadUsers - Boolean - User export  flag.
//	CollapseElementsInUsersCatalog - Boolean - User collapse flag.
//	UserMatching - ValueTable - Details See ExportImportData.DownloadCurAreaDataFromArchive
//                                                ().
//	ExtensionData_ - Structure - Contains information on the area key and extensions to be restored:
//		* DataAreaKey - String - data area key
//		* RecoveryExtensions - Array - the list of extensions to be restored.
//  ImportParameters - Structure, Undefined - Import parameters.: 
//      * StateID - UUID, Undefined - If passed, the execution state will be recorded during execution and progress will be calculated. The ID will be used as an entry key in the ExportImportDataAreasStates register.
//		
// Returns:		
//  Structure - with the following fields::
//  * Warnings - Array of String - User notifications following the import.
//
Function DownloadDifferentialCopy(
	Val FullArchive,
	Val DifferentialArchive,
	Val UploadUsers = False,
	Val CollapseElementsInUsersCatalog = False,
	UserMatching = Undefined,
	ExtensionData_ = Undefined,
	ImportParameters = Undefined) Export

	BackupTypeFull = ExportImportDataInternal.BackupTypeFull();
	BackupTypeDifferential = ExportImportDataInternal.BackupTypeDifferential();
	
	If ExportImportData.ItIsNecessaryToRecordExportImportDataAreaState(ImportParameters) Then
		
		FullCopyImportedObjectsCount = ExportImportDataInternal.NumberOfBackupObjectsToImport(
			FullArchive,
			BackupTypeFull,
			False);

		DifferentialCopyImportObjectsCount = ExportImportDataInternal.NumberOfBackupObjectsToImport(
			DifferentialArchive,
			BackupTypeDifferential,
			False);
		
		ImportParameters.Insert(
			"TotalObjectCount",
			FullCopyImportedObjectsCount + DifferentialCopyImportObjectsCount);
			
	EndIf;
	
	DownloadingFullArchiveResult = ImportCurrentArea(
		FullArchive, 
		False, 
		False, 
		Undefined, 
		ExtensionData_, 
		BackupTypeFull, 
		Undefined,
		ImportParameters);
	
	ResultOfImportDifferentialArchive = ImportCurrentArea(
		DifferentialArchive, 
		UploadUsers, 
		CollapseElementsInUsersCatalog, 
		UserMatching, 
		ExtensionData_, 
		BackupTypeDifferential, 
		DownloadingFullArchiveResult.RefsMap,
		ImportParameters);
		
	CommonClientServer.SupplementArray(
		ResultOfImportDifferentialArchive.Warnings,
		DownloadingFullArchiveResult.Warnings);
	
	ResultOfImportDifferentialArchive.Delete("RefsMap");
		
	Return ResultOfImportDifferentialArchive;
	
EndFunction

// Checks whether the exported data is compatible with the infobase configuration.
//
// Parameters:
//  ArchiveName - String - path to export file.
//
// Returns: 
//	Boolean - True if the archive data can be imported
//  	to the current configuration.
//
Function UploadingToArchiveIsCompatibleWithCurConfiguration(Val ArchiveName) Export

	Return ExportImportData.UploadingToArchiveIsCompatibleWithCurConfiguration(ArchiveName);

EndFunction

// Checks whether the exported data is compatible with the infobase configuration.
//
// Parameters:
//  ArchiveName - String - path to export file.
//
Procedure CheckIfUploadingToArchiveIsCompatibleWithCurConfiguration(Val ArchiveName) Export
	
	Directory = GetTempFileName();
	CreateDirectory(Directory);
	Directory = Directory + GetPathSeparator();
	
	Archiver = New ZipFileReader(ArchiveName);
	
	Try
		
		UploadDescriptionElement = Archiver.Items.Find("DumpInfo.xml");
		
		If UploadDescriptionElement = Undefined Then
			Raise StrTemplate(NStr("en = 'The %1 file is missing from the export file';"), "DumpInfo.xml");
		EndIf;
		
		Archiver.Extract(UploadDescriptionElement, Directory, ZIPRestoreFilePathsMode.Restore);
		
		UploadDescriptionFile = Directory + "DumpInfo.xml";
		
		UploadInformation = ExportImportDataInternal.ReadXDTOObjectFromFile(
			UploadDescriptionFile, XDTOFactory.Type("http://www.1c.ru/1cFresh/Data/Dump/1.0.2.1", "DumpInfo"));
		
		ExportImportDataInternal.CheckIfUploadingToArchiveIsCompatibleWithCurConfiguration(UploadInformation);
		ExportImportDataInternal.CheckIfUploadingToArchiveIsCompatibleWithCurVersionOfConfiguration(UploadInformation);
		
		ExportImportDataInternal.DeleteTempFile(Directory);
		Archiver.Close();
		
	Except
		
		ExportImportDataInternal.DeleteTempFile(Directory);
		Archiver.Close();
		
		Raise;
		
	EndTry;
	
EndProcedure

// Gets a data model to the subsequent data export or import
//
// Returns: 
//	Array of MetadataObject - types.
Function GetAreaDataModelTypes() Export

	Result = New Array();

	ModuleSaaSOperations = Common.CommonModule("SaaSOperations");
	DataModel = ModuleSaaSOperations.GetAreaDataModel();

	For Each DataModelItem In DataModel Do

		MetadataObject = Metadata.FindByFullName(DataModelItem.Key);

		If Not CommonCTL.IsScheduledJob(MetadataObject)
				And Not CommonCTL.IsDocumentJournal(MetadataObject)
				And Not CommonCTL.ThisIsExternalDataSource(MetadataObject) Then

			Result.Add(MetadataObject);

		EndIf;

	EndDo;

	Return Result;

EndFunction

// Returns the filename of the full archive.
//
// Returns:
//	String - File name of the full archive.
//
Function FullArchiveFileName_() Export 
	Return "full_data_dump.zip";	
EndFunction

#Region ObsoleteProceduresAndFunctions

// Deprecated. Instead, use ExportImportDataAreas. Exports application data to a ZIP archive.
// Later, the data can be imported from this archive to other infobases or data areas
//  by using function ExportImportData.ImportDataFromArchive().
//  
//
// Parameters:
//	DataAddress - String - a temporary storage address where the result must be stored, if this parameter is filled in
//	ExportModeForTechnicalSupport - Boolean - export flag in the mode for technical support
//
// Returns:
//	String - path to export file.
//
Function UploadCurDataAreaToArchive(Val DataAddress = Undefined,
		ExportModeForTechnicalSupport = False) Export
	
	FileName = UploadCurAreaToArchive(, ExportModeForTechnicalSupport).FileName;
		
	If DataAddress <> Undefined Then
		PutToTempStorage(FileName, DataAddress);
	EndIf;
	
	Return FileName;

EndFunction

// Deprecated. Obsolete. Use ExportCurrentDataAreaToArchive
// Exports application data to a ZIP archive, splits it into parts
// if necessary, and puts the result to a temporary storage.
//
// Parameters:
//	StorageAddress - String - a temporary storage address to place result
//	FileStorageAddress - String - a temporary storage address to place file
//	IsWebClient - Boolean - a web client flag
//	PartSizeInMegabytes - Number - size of one file part in megabytes
//	ExportModeForTechnicalSupport - Boolean - export flag in the mode for technical support
//
Procedure DumpCurDataAreaIntoFileAndSplitItIntoParts(StorageAddress,
		FileStorageAddress, IsWebClient, PartSizeInMegabytes = 0,
		ExportModeForTechnicalSupport = False) Export

	FileName = UploadCurAreaToArchive(, ExportModeForTechnicalSupport).FileName;

	Try

		PartsOfFile = SplitFileIntoParts(FileName, IsWebClient, PartSizeInMegabytes);

		If TypeOf(PartsOfFile) = Type("BinaryData") Then

			PutToTempStorage(PartsOfFile, FileStorageAddress);
			PutToTempStorage(FileStorageAddress, StorageAddress);

		Else

			PutToTempStorage(PartsOfFile, StorageAddress);

		EndIf;

		ExportImportDataInternal.DeleteTempFile(FileName);

	Except

		ExceptionText = CloudTechnology.DetailedErrorText(ErrorInfo());

		ExportImportDataInternal.DeleteTempFile(FileName);

		Raise ExceptionText;

	EndTry;

EndProcedure

// Deprecated. Imports application data from a ZIP archive containing XML files.
// 
//
// Parameters:
//  ArchiveName - String - a full name of an archive data file
//	UploadUsers - Boolean - indicates whether it is required to import user
//	CollapseElementsInUsersCatalog - Boolean - indicates whether it is required to collapse users
//	UserMatching - ValueTable - Details See ExportImportData.DownloadCurAreaDataFromArchive
//                                                ()
//	ExtensionData_ - Structure - Contains information on the area key and extensions to be restored:
//		* DataAreaKey - String - data area key
//		* RecoveryExtensions - Array - the list of extensions to be restored.
//
Procedure ImportCurrentDataAreaFromArchive(Val ArchiveName,
		Val UploadUsers = False,
		Val CollapseElementsInUsersCatalog = False,
		UserMatching = Undefined,
		ExtensionData_ = Undefined) Export
		
		ImportCurrentAreaFromArchive(
			ArchiveName,
			UploadUsers,
			CollapseElementsInUsersCatalog,
			UserMatching,
			ExtensionData_);
EndProcedure

#EndRegion

#EndRegion

#Region Private

// Splits a file into parts on the server and puts these parts to a temporary directory.
//
// Parameters:
//   FileName               - String - a name of the file that needs to be split into parts.
//   PartSizeInMegabytes - Number - size of one file part in megabytes.
// 
// Returns:
//   Array - Received file parts, a structure with the following keys:
//     * Location - String - a file location on the server,
//     * HashSum - Number - a hash sum value received by the CRC32 function.
//
Function SplitFileIntoParts(FileName, IsWebClient, PartSizeInMegabytes = 0)

	Result = New Array;

	// Chunk size in bytes. By default, 100 MB.
	PartSize = ?(PartSizeInMegabytes <= 0, 100, PartSizeInMegabytes)
		* 1024 * 1024;

		// Determining whether it is necessary to split the file.
	If IsWebClient Then

	// Web client does not support file merging.
		Separate = False;

	Else

	// Check the file size.
		SharedFile = New File(FileName);
		Separate = SharedFile.Size() > PartSize;

	EndIf;

	If Separate Then

		Try

		// Create a temporary directory for storing file chunks. If separation fails, the directory is deleted.
		// The names of the created files remain unknown if separation fails.
			TempDirectory = GetTempFileName();
			CreateDirectory(TempDirectory);

			// Splitting a file into parts.
			SegmentNames = SplitFile(FileName, PartSize, TempDirectory);

			For Each PartName In SegmentNames Do

			// For each filename, its checksum is saved to prevent getting another file.
			// When requesting a file chunk, the client must provide the filename and specify the checksum.
				DataHashing = New DataHashing(HashFunction.CRC32);
				DataHashing.AppendFile(PartName);

				Result.Add(New FixedStructure("Location, HashSum", PartName, DataHashing.HashSum));

			EndDo;

		Except // Cannot split the file for some reasons.

		// Deleting a temporary directory with the created file parts.
			ExportImportDataInternal.DeleteTempFile(TempDirectory);

			// Cannot split the file, return the file itself.
			Separate = False;

		EndTry;

	EndIf;

	// There is no need to split the file or failed to split, return the file itself.
	If Not Separate Then

		Result = New BinaryData(FileName);

	EndIf;

	Return Result;

EndFunction

Function ImportCurrentArea(
	Val Archive,
	Val UploadUsers,
	Val CollapseElementsInUsersCatalog,
	UserMatching,
	ExtensionData_,
	BackupType,
	RefsMap,
	ImportParameters)
	
	If ValueIsFilled(ImportParameters) Then
		ImportingParametersInternal = New Structure(New FixedStructure(ImportParameters));
	Else
		ImportingParametersInternal = New Structure();
	EndIf;
	
	If SaaSOperations.DataSeparationEnabled() Then
		UploadUsers = False;
		UploadUserSettings_ = False;
	Else
		UploadUsers = UploadUsers;
		UploadUserSettings_ = UploadUsers;
	EndIf;
	
	ImportingParametersInternal.Insert("UploadUsers", UploadUsers);
	ImportingParametersInternal.Insert("UploadUserSettings_", UploadUserSettings_);
		
	ImportingParametersInternal.Insert("CollapseSeparatedUsers", CollapseElementsInUsersCatalog);

	If UserMatching <> Undefined Then
		ImportingParametersInternal.Insert("UserMatching", UserMatching);
	EndIf;

	If ExtensionData_ <> Undefined Then
		ImportingParametersInternal.Insert("ExtensionData_", ExtensionData_);
	EndIf;
	
	ImportingParametersInternal.Insert("BackupType", BackupType);
	
	If RefsMap <> Undefined Then
		ImportingParametersInternal.Insert("RefsMap", RefsMap);
	EndIf;
	
	If Not ImportingParametersInternal.Property("ThreadsCount") Then
		ImportingParametersInternal.Insert("ThreadsCount", 0);
	EndIf;
	
	If ImportingParametersInternal.ThreadsCount < 1 Then
		ImportingParametersInternal.ThreadsCount = 1;
	EndIf;
	
	Return ExportImportData.DownloadCurAreaDataFromArchive(Archive, ImportingParametersInternal);
	
EndFunction

Procedure PlaceImportingResultInTemporaryStorage(ImportParameters, ImportResult1)
	ResultStorageAddress_ = Undefined;
	If ImportParameters = Undefined 
		Or Not ImportParameters.Property("ResultStorageAddress_", ResultStorageAddress_) Then
		Return;
	EndIf;
	PutToTempStorage(ImportResult1, ResultStorageAddress_);
EndProcedure

#EndRegion